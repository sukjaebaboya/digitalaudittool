<!DOCTYPE html>
<html lang="en">

<head>
    <link rel="stylesheet" href="conc.css">


    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>디지털 감리 보조 도구(콘크리트 표면결함)</title>

    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-LLEB9RM521');
    </script>

</head>

<body>
    <h1 class="title">디지털 감리 보조 도구(콘크리트 표면결함)</h1>
    <h2 class="subtitle"></h2>
    <h1 class="title">원하는 대상을 정 가운데로 위치해 주세요.</h1>
    <h2 class="subtitle">"시작하기!를 누르고 5초 기다려 주세요."</h2>
    <div class="image-upload-wrap">
        <canvas id="facecanvas"></canvas>

        <!-- Video that handles the browser access to the camera. The transforms mirror the feed -->
        <div id="file-upload-input">
            <video autoplay muted hidden playsinline id="video" style="
    -webkit-transform: scaleX(-1);
    transform: scaleX(-1);
    width: auto;
    height: auto;">
            </video>
        </div>
    </div>
    <div class="image-title-wrap">
        <button class="file-upload-btn" type="button" onclick="init()">시작하기!</button>
        <button class="file-upload-btn-red" type="button" onclick="abort = true">일시정지!</button>

    </div>
    <div class="resultData">
        <div id="label-container"></div>
        <div id="label-container2"></div>
        <div id="resultTitle"></div>
        <div id="resultExplain"></div>
        <div id="resultCeleb"></div>
    </div>
    <button class="return-home" onclick="location.href='https://dktool.netlify.app';"><span>홈화면으로 돌아가기</span></button>

    <!--button class="return-home" type="button" onclick="location.href='https://dktool.netlify.app/main.html';">홈으로 돌아가기</button-->


    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">

        // More API functions here:
        // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
        //document.getElementById("label-container").style.display = 'none'; //여기서 결과 가시성 설정함.
        //document.getElementById("label-container2").style.display = 'none';

        // the link to your model provided by Teachable Machine export panel

        //const URL = "https://teachablemachine.withgoogle.com/models/tIGFq2epH/"; //여기를 나중에 로컬 경로로 수정할 것. 
        //const URL = "C:/Users/wonju/OneDrive/Desktop/Structure_Image_Analysis/tm-my-image-model/";

        const URL = "https://teachablemachine.withgoogle.com/models/kx8FXr73V/"; //여기를 나중에 로컬 경로로 수정할 것. 구조부재인지 아닌지 여기서 파악.
        const URL2 = "https://teachablemachine.withgoogle.com/models/A22tGftrI/"; 


        let model, webcam, labelContainer, maxPredictions, result1;
        //const URL = "C:/Users/wonju/OneDrive/Desktop/Structure_Image_Analysis/tm-my-image-model/";
        let model2, webcam2, labelContainer2, maxPredictions2, result2;
        //const URL = "C:/Users/wonju/OneDrive/Desktop/Structure_Image_Analysis/tm-my-image-model/";

        var img1 = document.createElement("img");
        var abort = false;


        // Load the image model and setup the webcam
        async function init() {
            
            abort = false;

            const modelURL = URL + "model.json"; //이 부분에서 5초간 대기 시간이 발생함.
            const metadataURL = URL + "metadata.json";

            const modelURL2 = URL2 + "model.json";
            const metadataURL2 = URL2 + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)
            model = await tmImage.load(modelURL, metadataURL);
            model2 = await tmImage.load(modelURL2, metadataURL2);
            maxPredictions = model.getTotalClasses();
            maxPredictions2 = model2.getTotalClasses();

            // Convenience function to setup a webcam
            /*const flip = true; // whether to flip the webcam
            webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
            await webcam.setup(); // request access to the webcam
            await webcam.play();
            */

            // append elements to the DOM



            //window.requestAnimationFrame(loop);
            if (window.requestAnimationFrame) { window.requestAnimationFrame(loop); }
            else if (window.webkitRequestAnimationFrame) { window.webkitRequestAnimationFrame(loop); }
            else if (window.mozRequestAnimationFrame) { window.mozRequestAnimationFrame(loop); }
            else if (window.oRequestAnimationFrame) { window.oRequestAnimationFrame(loop); }
            else if (window.msRequestAnimationFrame) { window.msRequestAnimationFrame(loop); }
            else { alert("지원하지 않는 브라우저!"); }

            //document.getElementById("webcam-container").appendChild(webcam.canvas);

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)


            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
                labelContainer.appendChild(document.createElement("div"));
            }
            labelContainer2 = document.getElementById("label-container2");
            for (let i = 0; i < maxPredictions2; i++) { // and class labels
                labelContainer2.appendChild(document.createElement("div"));
            }
        }


        function delay(time) {
            return new Promise(resolve => setTimeout(resolve, time));
        }



        async function loop() {
            window.speechSynthesis.cancel();
            //webcam.update(); // update the webcam frame

            var asdf = document.getElementsByTagName('video');
            var imgCanvas = document.createElement('canvas');
            imgCanvas.width = video.videoWidth;
            imgCanvas.height = video.videoHeight;
            imgCanvas.getContext('2d').drawImage(video, 0, 0, video.videoWidth, video.videoHeight);

            const dataURL = imgCanvas.toDataURL();
            img1.src = dataURL;

            await predict2(); //처음 실행만 안됨. 어째서?
            await predict2(); //여기부터 실행 잘됨. 
            await predict();

            resultsay();
            await delay(1000); //시간 조절은 여기서.
            imgCanvas.remove();
            //window.requestAnimationFrame(loop);
            if (window.requestAnimationFrame) { window.requestAnimationFrame(loop); }
            else if (window.webkitRequestAnimationFrame) { window.webkitRequestAnimationFrame(loop); }
            else if (window.mozRequestAnimationFrame) { window.mozRequestAnimationFrame(loop); }
            else if (window.oRequestAnimationFrame) { window.oRequestAnimationFrame(loop); }
            else if (window.msRequestAnimationFrame) { window.msRequestAnimationFrame(loop); }
            else { alert("지원하지 않는 브라우저!"); }
        }







        // run the webcam image through the image model
        async function predict() {
            // predict can take in an image, video or canvas html element
            const prediction = await model.predict(img1, false);
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                labelContainer.childNodes[i].innerHTML = classPrediction;
            }

            prediction.sort((a, b) => parseFloat(b.probability) - parseFloat(a.probability));
            result1 = (prediction[0].className);
            console.log(result1)

        }


        // run the webcam image through the image model
        async function predict2() {
            // predict can take in an image, video or canvas html element
            const prediction2 = await model2.predict(img1, false);
            for (let i = 0; i < maxPredictions2; i++) {
                const classPrediction2 =
                    prediction2[i].className + ": " + prediction2[i].probability.toFixed(2);
                labelContainer2.childNodes[i].innerHTML = classPrediction2;
            }
            prediction2.sort((a2, b2) => parseFloat(b2.probability) - parseFloat(a2.probability));
            result2 = (prediction2[0].className);
            console.log(result2)
        }

        let resultTitle, resultExplain, resultCeleb;
        resultTitle = "";
        resultExplain = "";
        resultCeleb = "";

        var resultTitleContainer = document.getElementById("resultTitle");
        var txt1 = document.createTextNode(resultTitle);
        resultTitleContainer.appendChild(document.createElement("h1")).appendChild(txt1);

        var resultExplainContainer = document.getElementById("resultExplain");
        var txt2 = document.createTextNode(resultExplain);
        resultExplainContainer.appendChild(document.createElement("p")).appendChild(txt2);

        var resultCelebContainer = document.getElementById("resultCeleb");
        var txt3 = document.createTextNode(resultCeleb);
        resultCelebContainer.appendChild(document.createElement("p")).appendChild(txt3);


        async function resultsay() {
            const resultCom = (result1 + "+" + result2)
            console.log(resultCom)
            console.log("toc")
            // switch (prediction[0].className) {
            switch (resultCom) {
                case "ConcreteColumn+Efflorescence":
                    resultTitle = "기둥의 백화현상"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteColumn+popout":
                    resultTitle = "기둥의 팝아웃"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteColumn+Segregation":
                    resultTitle = "기둥의 재료분리"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteColumn+Spalling":
                    resultTitle = "기둥의 박리"
                    resultExplain = ""
                    resultCeleb = " "
                    break;
                    case "ConcreteBeam+Efflorescence":
                    resultTitle = "보의 백화현상"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteBeam+popout":
                    resultTitle = "보의 팝아웃"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteBeam+Segregation":
                    resultTitle = "보의 재료분리"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteBeam+Spalling":
                    resultTitle = "보의 박리"
                    resultExplain = ""
                    resultCeleb = " "
                    break;
                    case "ConcreteWall+Efflorescence":
                    resultTitle = "벽의 백화현상"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteWall+popout":
                    resultTitle = "벽의 팝아웃"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteWall+Segregation":
                    resultTitle = "벽의 재료분리"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "ConcreteWall+Spalling":
                    resultTitle = "벽의 박리"
                    resultExplain = ""
                    resultCeleb = " "
                    break;
                case "BlockWall+Efflorescence":
                    resultTitle = "벽돌벽의 백화현상"
                    resultExplain = ""
                    resultCeleb = ""
                    break;
                case "Plane+Efflorescence":
                    resultTitle = "균열부위가 아닌 것 같아요. 좀 더 자세하게 보여주세요."
                    resultExplain = "1~2미터 간격에서 찍어주세요."
                    resultCeleb = " "
                    break;
                case "Plane+popout":
                    resultTitle = "균열부위가 아닌 것 같아요. 좀 더 자세하게 보여주세요."
                    resultExplain = "1~2미터 간격에서 찍어주세요."
                    resultCeleb = " "
                    break;
                case "Plane+Segregation":
                    resultTitle = "균열부위가 아닌 것 같아요. 좀 더 자세하게 보여주세요."
                    resultExplain = "1~2미터 간격에서 찍어주세요."
                    resultCeleb = " "
                    break;
                case "Plane+Spalling":
                    resultTitle = "균열부위가 아닌 것 같아요. 좀 더 자세하게 보여주세요."
                    resultExplain = "1~2미터 간격에서 찍어주세요."
                    resultCeleb = " "
                    break;
                default:
                    resultTitle = "균열부위가 아닌 것 같아요. 좀 더 자세하게 보여주세요."
                    resultExplain = "1~2미터 간격에서 찍어주세요."
                    resultCeleb = " "
                //code
            }


            var resultTitleContainer11 = document.getElementById("resultTitle");
            resultTitleContainer11.firstChild.firstChild.nodeValue = resultTitle;

            var resultTitleContainer22 = document.getElementById("resultExplain");
            resultTitleContainer22.firstChild.firstChild.nodeValue = resultExplain;

            var resultTitleContainer33 = document.getElementById("resultCeleb");
            resultTitleContainer33.firstChild.firstChild.nodeValue = resultCeleb;

            //let voices;
            //voices = window.speechSynthesis.getVoices();

            if (abort == false) {
                var msg = new SpeechSynthesisUtterance();
                //msg.voice = voices[12];
                msg.text = resultTitle;
                msg.rate = 1.5;
                //msg.lang = 'ko-KR';
                window.speechSynthesis.speak(msg);
                //return new Promise(resolve => {msg.onend = resolve;});
            }


            /*
                        var msg2 = new SpeechSynthesisUtterance();
                        //msg2.voice = voices[12];
                        msg2.text = resultExplain;
                        msg2.rate = 1.2;
                        //msg2.lang = 'ko-KR';
                        window.speechSynthesis.speak(msg2);
                        //return new Promise(resolve => {msg2.onend = resolve;});
            
            
            
            
                        var msg3 = new SpeechSynthesisUtterance();
                        //msg3.voice = voices[12]; //목소리 톤이 아닌 이거 언어임.
                        msg3.text = resultCeleb;
                        msg3.rate = 1.2; //재생 속도는 여기서.
                        //msg3.lang = 'ko-KR'; //필요 X
                        window.speechSynthesis.speak(msg3);
                        //return new Promise(resolve => {msg3.onend = resolve;});
            */



            /*
            for(var i = 0; i < voices.length; i++)
            {
            console.log(voices[i].name);
            }
            */


        }










        // Camera setup function - returns a Promise so we have to call it in an async function
        async function setupCamera() {
            // Find the video element on our HTML page
            video = document.getElementById('video');

            // Request the front-facing camera of the device
            const stream = await navigator.mediaDevices.getUserMedia({
                'audio': false,
                'video': {
                    facingMode: "environment",
                },
            });
            video.srcObject = stream;

            // Handle the video stream once it loads.
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function drawWebcamContinuous() {
            ctx.drawImage(video, 0, 0);

            //무한루프.



            //반복 안함. why?
            //init();
            //predict();
            //predict2();

            //resultsay();
            //console.log('testing2');

            //await delay(5000); //시간 조절은 여기서.




            requestAnimationFrame(drawWebcamContinuous);




        }

        var canvas;
        var ctx;

        async function main() {
            // Set up front-facing camera
            try {
                await setupCamera();
                video.play()
            } catch { alert("카메라 인식 실패!"); }

            // Set up canvas for livestreaming
            canvas = document.getElementById('facecanvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx = canvas.getContext('2d');

            // Start continuous drawing function
            drawWebcamContinuous();

            console.log("Camera setup done")
        }

        // Delay the camera request by a bit, until the main body has loaded
        document.addEventListener("DOMContentLoaded", main);




    </script>




</body>

</html>
